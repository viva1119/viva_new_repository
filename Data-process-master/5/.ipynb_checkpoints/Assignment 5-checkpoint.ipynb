{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.api as sm\n",
    "import tflearn \n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import pylab as pl\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('data.csv')\n",
    "X = dataset.iloc[:, 18: 20].values\n",
    "y = dataset.iloc[:, 12].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.08, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting model parameters\n",
    "learning_rate = 0.05\n",
    "training_epochs = 50\n",
    "train_epoch=50\n",
    "batch_size = 50\n",
    "batch_size = 40\n",
    "batch_num=4000/batch_size\n",
    "display_step = 1\n",
    "n_sample = X_train.shape[0]\n",
    "\n",
    "n_input = X_train.shape[1]\n",
    "n_hidden_1 = 64\n",
    "n_hidden_2 = 64\n",
    "n_hidden_3 = 64\n",
    "n_class = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder settings\n",
    "x = tf.placeholder('float', [None, n_input])\n",
    "y = tf.placeholder('float', [None, n_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining MLP model\n",
    "\n",
    "def multilayer_perceptron(x, weights, biases, drop_out):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # layer_2 = tf.nn.dropout(layer_2, drop_out)\n",
    "\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['w_out']) + biases['b_out']\n",
    "    return out_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining weight and bias\n",
    "weight = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])), \n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])), \n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_3, n_class]))\n",
    "}\n",
    "bias = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_2])), \n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_3])), \n",
    "    'out': tf.Variable(tf.random_normal([n_class]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build MLP model\n",
    "y_pred = multiplayer_perceptron(x, weight, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining cost function(using linear regression)\n",
    "cost = tf.reduce_mean(tf.square(y_pred-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizing\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing all the variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "train_loss = np.zeros(train_epoch)\n",
    "train_acc = np.zeros(train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-5aeaed135396>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             _, c = sess.run([optimizer, cost], feed_dict={x: X_train[i*batch_size : (i+1)*batch_size, :], \n\u001b[0;32m---> 11\u001b[0;31m                                                           y: y_train[i*batch_size : (i+1)*batch_size, :]})\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mavg_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(n_sample / batch_size)\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: X_train[i*batch_size : (i+1)*batch_size, :], \n",
    "                                                          y: y_train[i*batch_size : (i+1)*batch_size, :]})\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        plt.plot(epoch+1, avg_cost, 'co')\n",
    "\n",
    "        if epoch % display_step == 0:\n",
    "            print('Epoch:', '%04d' % (epoch+1), 'cost=', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "    print('Opitimization Finished!')\n",
    "\n",
    "    # Test\n",
    "    acc = accuracy.eval({x: X_test, y: y_test})\n",
    "    print('Accuracy:', acc)\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Cost')\n",
    "    plt.title('lr=%f, te=%d, bs=%d, acc=%f' % (learning_rate, training_epochs, batch_size, acc))\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-bc731dceb1ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0marr_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT_ind\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mbatch_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marr_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(0, train_epoch):\n",
    "        for batch in range (0, batch_num):\n",
    "            arr_3 = T_ind[ batch * batch_size : (batch + 1) * batch_size ]\n",
    "            batch_x = data_mat[arr_3, :]\n",
    "            batch_y = label_y[arr_3, :]\n",
    "            # Run optimization op (backprop)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "        # Calculate loss and accuracy\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict={x: data_mat,\n",
    "                                                          y: label_y})\n",
    "\n",
    "\n",
    "        train_loss[epoch] = loss\n",
    "        train_acc[epoch] = acc\n",
    "\n",
    "\n",
    "        print(\"Epoch: \" + str(epoch+1) + \", Loss= \" + \\\n",
    "                  \"{:.3f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(train_loss, 'r')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training loss\")\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel('Training Accuracy')\n",
    "plt.ylim(0.0, 1)\n",
    "plt.plot(train_acc, 'r')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
